import abc
from typing import Dict

import numpy as np

''' Remove later'''
import struct
def binary(num):  # converts a float to binary, 8 bits
    '''
    Function for float to binary from here:
    https://stackoverflow.com/questions/16444726/binary-representation-of-float-in-python-bits-not-hex
    '''

    return ''.join('{:0>8b}'.format(c) for c in struct.pack('!f', num))


class TMUDataset:

    def __init__(self):
        pass

    @abc.abstractmethod
    def booleanizer(self, name, dataset):
        raise NotImplementedError("You should override def threshold()")

    @abc.abstractmethod
    def retrieve_dataset(self) -> Dict[str, np.ndarray]:
        raise NotImplementedError("You should override def retrieve_dataset()")

    def get(self):
        return {k: self.booleanizer(k, v) for k, v in self.retrieve_dataset().items()}

    def get_list(self):
        return list(self.get().values())


class MNIST(TMUDataset):
    def retrieve_dataset(self) -> Dict[str, np.ndarray]:
        from keras.datasets import mnist
        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
        return dict(
            x_train=X_train,
            y_train=Y_train,
            x_test=X_test,
            y_test=Y_test
        )
    def booleanizer(self, name, dataset):
        if name.startswith("y"):
            return dataset
        return np.where(dataset.reshape((dataset.shape[0], 28*28)) > 75, 1, 0)

class KDD99(TMUDataset):
    def __init__(self, split=0.7, shuffle=False):
        self.split = split
        self.shuffle = shuffle

    def retrieve_dataset(self) -> Dict[str, np.ndarray]:
        from sklearn.datasets import fetch_openml
        import math
        print("Loading KDDCup99 dataset...")
        kdd = fetch_openml(name='KDDCup99', parser="auto", version=1)
        data = kdd['data']
        labels = kdd['target']

        # If Shuffle flag is set, shuffle the data
        if self.shuffle:
            print("Shuffling data...")
            from random import shuffle
            temp_data = []
            temp_labels = []
            temp_storage = []
            for x in data.iterrows():
                temp_data.append(x[1])

            for y in labels.items():
                temp_labels.append(y[1])

            for i, x in enumerate(temp_data):
                temp_storage.append((temp_data[i],temp_labels[i]))
            shuffle(temp_storage)
            new_data = []
            new_labels = []
            for temp in temp_storage:
                new_data.append(temp[0])
                new_labels.append(temp[1])
            data = new_data
            labels = new_labels

        print(set(labels))
        # Split data into training and testing sets with a given split (default 0.7/0.3)
        print("Dividing data into training and test with a",self.split,"split...")
        N_split = math.floor(self.split*len(data))
        X_train = data[0:N_split]
        Y_train = labels[0:N_split]
        X_test = data[N_split:]
        Y_test = labels[N_split:]

        return dict(
                x_train=X_train,
                y_train=Y_train,
                x_test=X_test,
                y_test=Y_test
            )
    def booleanizer(self, dataset, max_bits, database, registry):
        ''' 
        Custom booleanizer for our project, TODO: generalize
        '''
        print("Binarizing...")
        data_values = []
        data = dataset

        # output: dictionary with keys "x_train/x_test" for data and "y_train/y_test" for labels
        # cicids output:
        # Duplicate the registry, add new keys to it
        reg = registry
        db = database
        for new_label in dataset["y_train"]+dataset["y_test"]:
            if new_label not in reg.keys():
                reg[new_label] = 0
                db[new_label] = []
        data = dataset["x_train"]+dataset["x_test"]
        labels = dataset["y_train"]+dataset["y_test"]
        for i, row in enumerate(data):  # numerically iterate through every line of data
            datapoint = []  # empty list to hold the features of each row
            for item in row:  # for each value in a row
                datapoint.append(item)  # add it to the list of features for this row
            datapoint.append(labels[i])
            data_values.append(datapoint)  # add the final list of features for this row to the processed dataset

        for item in data_values:  # for each dataset item
            values = item[0:-1]
            label = item[-1]
            rowie = ""  # string to temporarily hold binary representation of the data item
            non_floatable = []
            for feature in values:  # for each value / feature in said item_
                try:
                    kek = float(feature)
                except:
                    if feature not in non_floatable:
                        non_floatable.append(feature)
                    kek = float(non_floatable.index(feature))

                rowie += str(binary(kek))[-max_bits:]  # concatenate the binary string for each feature to the string representing the item
            db[label].append([*rowie])
            registry[label] += 1
        print(registry)
        print("Binarizing done")
        return (db, registry)  # returns tuple of binary representation of data item and its label as an integer, and the string of labels for later decoding.


class NSLKDD(TMUDataset):
    def retrieve_dataset(self) -> Dict[str, np.ndarray]:
        from keras.datasets import mnist
        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
        return dict(
            x_train=X_train,
            y_train=Y_train,
            x_test=X_test,
            y_test=Y_test
        )
    def booleanizer(self, name, dataset):
        if name.startswith("y"):
            return dataset

        return np.where(dataset.reshape((dataset.shape[0], 28*28)) > 75, 1, 0)


class CICIDS2017(TMUDataset):
    def retrieve_dataset(self) -> Dict[str, np.ndarray]:
        from keras.datasets import mnist
        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
        return dict(
            x_train=X_train,
            y_train=Y_train,
            x_test=X_test,
            y_test=Y_test
        )
    def booleanizer(self, name, dataset):
        if name.startswith("y"):
            return dataset

        return np.where(dataset.reshape((dataset.shape[0], 28*28)) > 75, 1, 0)


class UNSWNB15(TMUDataset):
    def retrieve_dataset(self) -> Dict[str, np.ndarray]:
        from keras.datasets import mnist
        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
        return dict(
            x_train=X_train,
            y_train=Y_train,
            x_test=X_test,
            y_test=Y_test
        )
    def booleanizer(self, name, dataset):
        if name.startswith("y"):
            return dataset

        return np.where(dataset.reshape((dataset.shape[0], 28*28)) > 75, 1, 0)


class HIKARI2021(TMUDataset):
    def retrieve_dataset(self) -> Dict[str, np.ndarray]:
        from keras.datasets import mnist
        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()
        return dict(
            x_train=X_train,
            y_train=Y_train,
            x_test=X_test,
            y_test=Y_test
        )

    def booleanizer(self, name, dataset):
        if name.startswith("y"):
            return dataset

        return np.where(dataset.reshape((dataset.shape[0], 28*28)) > 75, 1, 0)

